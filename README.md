# IFCO Data Engineering Challenge

This challenge involves processing and analyzing datasets to answer various business-related tests. For this, I used:

- Databricks Community Edition (PySpark) for Tasks 1-5.
- Power BI for Task 6 (visualizations).

The PySpark notebook is divided into three sections:

- Loading and transforming orders.csv: Import, clean, and prepare data for analysis, then export it as CSV.
- Loading and transforming invoicing_data.json: Similar to the previous step but for invoicing data.
- Test completion: Solving the provided tests using the transformed data, with detailed code comments and unit tests.

[Databricks Notebook](https://community.cloud.databricks.com/editor/notebooks/4458272523191699?o=388291198913926)
